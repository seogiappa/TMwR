# 모델링 소프트웨어 {#software-modeling}

```{r software-setup, include = FALSE}
knitr::opts_chunk$set(fig.path = "figures/")
library(tidyverse)
library(gridExtra)
library(tibble)
library(kableExtra)

data(ames, package = "modeldata")
```


모델은 시스템을 설명하고 제공된 데이터의 관계를 캡처할 수 있는 수학적 도구입니다. 모델은 미래 이벤트 예측, 여러 그룹 간의 차이 여부 결정, 지도 기반 시각화 지원, 추가 조사가 가능한 데이터의 새로운 패턴 발견 등 다양한 목적으로 사용할 수 있습니다. 모델의 유용성은 _환원_ 능력에 달려 있습니다. 데이터의 주요 영향은 방정식으로 표현할 수 있는 관계와 같은 유용한 방식으로 수학적으로 캡처할 수 있습니다.  

21세기 초부터 수학적 모델은 명백하고 미묘한 방식으로 일상 생활에서 어디에나 존재하게 되었습니다. 많은 사람들의 일반적인 하루는 날씨를 확인하여 개를 산책시키기에 좋은 시간을 선택하고, 웹사이트에서 제품을 주문하고, 친구에게 문자 메시지를 입력하거나 자동으로 수정하고, 이메일을 확인하는 일이 포함될 수 있습니다. 이러한 각각의 경우에 어떤 유형의 모델이 관련되었을 가능성이 높습니다. 어떤 경우에는 모델의 사용을 쉽게 인식할 수 있지만('제품 X의 구매에 관심이 있을 수도 있음'), 그렇지 않은 경우도 있습니다(예: 스팸 이메일). 모델은 고객이 좋아할 만한 의복을 선택하고, 약물 후보로 평가될 분자를 식별하는 데 사용되거나, 심지어 사악한 회사가 과도하게 오염시키는 자동차의 발견을 피하기 위해 사용되는 메커니즘일 수도 있습니다. 좋든 나쁘든 모델은 계속 존재합니다.  

:::rmdnote
모델이 오늘날 우리 삶에 스며든 두 가지 이유가 있습니다. 모델을 생성하기 위한 풍부한 **소프트웨어**가 존재하고 **데이터**를 기록하고 접근하는 것이 더 쉬워졌습니다. 
:::

이 책은 주로 소프트웨어에 중점을 둡니다. 소프트웨어가 데이터를 표현하기 위해 정확한 관계를 생성하는 것은 매우 중요합니다. 대부분의 경우 수학적 정확성을 결정하는 것이 가능하지만 적절한 모델을 안정적으로 생성하려면 다음과 같은 것들이 더 필요합니다. 

첫째, 소프트웨어를 적절한 방식으로 쉽게 운용하는 것이 중요합니다. 사용자가 부적절하게 사용했다는 사실을 모를 정도로 사용자 인터페이스가 잘못 설계되어서는 안 됩니다. 예를 들어, Baggerly와 @baggerly2009는 세간의 이목을 끄는 컴퓨터 생물학 출판물의 데이터 분석에서 무수히 많은 문제를 보고했습니다. 문제 중 하나는 사용자가 모델 입력의 이름을 추가해야 하는 방법과 관련이 있었습니다. 소프트웨어의 사용자 인터페이스를 통해 실제 데이터 열에서 데이터의 열 이름을 쉽게 오프셋 할 수 있었습니다. 이로 인해 잘못된 유전자가 암 환자 치료에 중요한 것처럼 잘못 여겨졌고, 결국 여러 임상 시험이 종료되었습니다[@Carlson2012].

고품질 모델이 필요한 경우 소프트웨어를 적절하게 사용할 수 있어야 합니다. @abrams2003는 다음과 같은 흥미로운 원칙을 설명합니다:

> 성공의 중심: 정상에 오르기 위해서는 수많은 시행착오가 필요하지만, 우리가 고객에게 바라는 것은 우리의 플랫폼과 프레임워크를 사용하여 쉽게 원하는 목표를 달성하는 것입니다. 

데이터 분석 및 모델링 소프트웨어는 이 아이디어를 따라야 합니다. 

모델 구축의 두 번째 중요한 측면은 과학적 방법론과 관련이 있습니다. 복잡한 예측 모델로 작업할 때 논리적 오류 또는 부적절한 가정과 관련된 오류를 무의식적으로 범하기 쉽습니다. 많은 기계 학습 모델은 패턴 발견에 매우 능숙하여 나중에 재현되지 않는 데이터로부터 경험적 패턴을 쉽게 찾을 수 있습니다. 그러나, 이러한 유형의 방법론적 오류 중 일부는 실제 결과가 포함된 새 데이터를 얻을 때까지 문제가 감지되지 않을 수 있다는 점에서 조심해야 합니다.

:::rmdwarning
모델이 더욱 강력하고 복잡해짐에 따라 잠재적인 오류를 범하기도 더 쉬워집니다. 
:::

이 동일한 원칙은 프로그래밍에도 적용됩니다. 가능한 한 소프트웨어는 사용자가 **실수하지 않도록 보호**할 수 있어야 하고, **올바른 작업을 쉽게 수행**할 수 있도록 해야 합니다.

모델을 개발할 때는 이 두 가지 측면이 중요합니다. 모델을 만들기 위한 도구는 쉽게 구할 수 있고, 모델은 큰 영향을 미칠 수 있기 때문에 많은 사람들이 모델을 만들고 있습니다. 기술 전문성 및 교육 측면에서 그들의 배경은 다양합니다. 도구가 사용자의 경험에 견고해야 한다는 것이 중요합니다. 도구는 고성능 모델을 생성할 수 있을 만큼 강력해야 하면서도 적절한 방식으로 사용하기 쉬워야 합니다. 이 책은 이러한 특성을 염두에 두고 설계된 모델링용 소프트웨어 제품군에 대해 설명합니다.

여기에서 사용된 소프트웨어는 R 프로그래밍 언어를 기반으로 합니다[@baseR]. R은 데이터 분석 및 모델링을 위해 특별히 설계되었으며, 1970년대에 "아이디어들을 빠르고 충실하게 소프트웨어로 바꾸기"[@Chambers:1998] 위해 만들어진 S 언어(Scheme 과Lisp로부터 채택된 사전 범위 지정 규칙 포함)의 구현입니다.

R은 오픈 소스이며 무료입니다. 다양한 용도로 사용할 수 있는 강력한 프로그래밍 언어이지만 데이터 분석, 모델링, 시각화 및 기계 학습에 특화되어 있습니다. R은 쉽게 확장할 수 있으며, 모델링, 시각화 등과 같은 특정 주제에 중점을 둔 대부분의 사용자 기여 모듈인 방대한 패키지 생태계를 가지고 있습니다.

패키지 중에 ***tidyverse*** 라는 묶음이 있습니다[@tidyverse]. tidyverse는 데이터 과학을 위해 설계된 R 패키지의 독창적인 모음입니다. 모든 패키지는 기본 디자인 철학, 문법 및 데이터 구조를 공유합니다. 이러한 설계 철학 중 일부는 이 섹션에서 설명하는 소프트웨어 측면에서 직접적으로 영향을 받습니다. tidyverse 패키지를 사용한 적이 없다면 \@ref(tidyverse)장에 기본 개념에 대한 검토가 포함되어 있습니다. tidyverse 내에서 특별히 모델링에 초점을 맞춘 패키지의 하위 집합을 ***tidymodels*** 패키지라고 합니다. 이 책은 tidyverse와 tidymodels를 사용하여 모델링을 수행하기 위한 확장된 소프트웨어 매뉴얼입니다. 각각 고유한 특정 목적을 가진 패키지 세트를 사용하여 고품질 모델을 만드는 방법을 보여줍니다.

## 모델 유형 {#model-types}

계속하기 전에 목적별로 그룹화된 모델 유형에 대한 분류를 설명하겠습니다. 완전하지는 않지만 대부분의 모델은 다음 범주 중 하나 이상에 속합니다:

### 서술적 모델(DESCRIPTIVE MODELS) {-}

서술적 모델의 목적은 데이터의 특성을 설명하거나 서술하는 것입니다. 서술적 분석은 데이터의 일부 추세 또는 인공물을 시각적으로 강조하는 것이 주 목적일 수 있습니다.

예를 들어, 한동안 마이크로어레이를 사용하여 RNA의 대규모 측정이 가능했습니다. 초기 실험실에서 사용된 방법은 생물학적 샘플을 작은 마이크로칩에 넣었습니다. 칩의 매우 작은 위치는 특정 RNA 시퀀스의 풍부함을 기반으로 신호를 측정할 수 있습니다. 칩에는 수천(또는 그 이상)의 결과가 포함될 것이며, 각각은 일부 생물학적 과정과 관련된 RNA의 정량화입니다. 그러나 칩의 품질에 문제가 있어서 결과가 좋지 않을 수 있습니다. 실수로 칩의 일부에 지문이 남아 있으면 스캔 시 부정확한 측정이 발생할 수 있습니다.

이러한 문제를 평가하는 초기 방법은 _프로브 수준 모델_ 또는 PLM이었습니다[@bolstad2004]. 이 모델을 통해 칩, RNA 서열, 서열 유형 등과 같은 데이터의 _알려진_ 차이점을 설명하는 통계 모델이 생성됩니다. 데이터에 알 수 없는 다른 요인이 있는 경우 이러한 효과는 모델 잔차에 캡처됩니다. 잔차가 칩의 위치에 따라 표시되는 반면 좋은 품질의 칩은 패턴을 표시하지 않습니다. 문제가 발생하면 일종의 공간 패턴을 식별할 수 있습니다. 종종 패턴 유형은 근본적인 문제(예: 지문)와 가능한 해결책(칩을 닦아내고 다시 스캔, 샘플 반복 등)을 제안합니다. 그림 \@ref(fig:software-descr-examples)(a)는 @Gentleman2005 에서 가져온 두 개의 마이크로어레이에 이 방법을 적용한 것을 보여줍니다. 이미지는 두 가지 다른 색상을 보여줍니다. 빨간색은 신호 강도가 모델이 예상한 것보다 큰 반면 파란색은 예상보다 낮은 값을 나타냅니다. 왼쪽 패널은 상당히 무작위적인 패턴을 보여주는 반면 오른쪽 패널은 칩 중앙에 바람직하지 않은 인공물을 나타냅니다.

```{r software-descr-examples, echo = FALSE, fig.cap = "특정 패턴을 설명하기 위해 서술적 모델을 사용하는 방법에 대한 두 가지 예.", out.width = '80%', dev = "png", fig.height = 8, warning = FALSE, message = FALSE}
load("RData/plm_resids.RData")

resid_cols <- RColorBrewer::brewer.pal(8, "Set1")[1:2]

# 빨간색은 강도가 예상보다 높은 지점입니다
plm_plot <- 
  plm_resids %>% 
  mutate(sign = ifelse(Intensity < 0, "low", "high")) %>% 
  ggplot(aes(x = x, y = y, fill = sign))  + 
  geom_tile(show.legend = FALSE) + 
  facet_wrap(~Sample) + 
  theme(
    panel.grid.major = element_blank(),
    panel.grid.minor = element_blank(),
    panel.background = element_blank(),
    axis.text.x = element_blank(),
    axis.text.y = element_blank(),
    axis.ticks = element_blank()
  ) + 
  labs(x = "", y = "") + 
  scale_fill_manual(values = c("#377EB8", "#E41A1C")) + 
  coord_equal() + 
  ggtitle("(a) 모델을 사용하여 두 개의 마이크로어레이 칩의 품질 평가.") + 
  theme(plot.title = element_text(hjust = 0.5))


ames_plot <- 
  ggplot(ames, aes(x = Latitude, y = Sale_Price)) + 
  geom_point(alpha = .2) + 
  geom_smooth(se = FALSE, method = stats::loess, method.args = list(span = .3), col = "red") + 
  scale_y_log10() + 
  ylab("House Sale Price ($US)") + 
  ggtitle("(b) 모델 기반 평활기를 사용하여 추세 발견.")

grid.arrange(plm_plot, ames_plot, ncol = 1)
```

서술적 모델의 또 다른 예는 LOESS [@cleveland1979]로 더 일반적으로 알려진 _지역 추정 산점도 평활 모델(locally estimated scatterplot smoothing model)_ 입니다. 여기에서 평활하고 유연한 회귀 모델은 일반적으로 단일 독립 변수가 있는 데이터 세트에 적합하며 적합 회귀선은 데이터의 일부 추세를 설명하는 데 사용됩니다. 이러한 유형의 평활기는 모델에서 변수를 나타내는 잠재적인 방법을 찾는데 사용됩니다. 이것은 그림 \@ref(fig:software-descr-examples)(b) 에서 비선형 추세가 유연한 평탄기에 의해 조명되는 곳에서 설명됩니다. 이 플롯에서 주택의 판매 가격과 위도 사이에는 매우 비선형적인 관계가 있음이 분명합니다.


### 추론 모델(INFERENTIAL MODELS) {-}

추론 모델의 목표는 통계적 테스트에서 사용되는 방식으로 연구 질문에 대한 결정을 내리거나 특정 가설을 테스트하는 것입니다^[많은 특정 통계 테스트는 실제로 모델과 동일합니다. 예를 들어, t-검정 및 분산 분석(ANOVA) 방법은 일반화 선형 모델의 특정 사례입니다.]. 즉, 미리 정의된 추측이나 아이디어에 대해 사실을 진술하는 것입니다. 추론 모델은 많은 경우(전부는 아님)에서 정성적인 설명이 생성됩니다(예: 차이가 '통계적으로 유의미함').

예를 들어, 어떤 임상 시험을 한다고 해봅시다. 이 임상 시험의 목표는 새로운 치료법이 기존 치료법이나 치료하지 않는 것보다 수명 연장에 더 효과적인지 아닌지를 확인하는 것입니다. 이 임상 시험에서  _귀무가설(null hypothesis)_ 은 두 치료 그룹의 중앙 생존 시간이 동일하고(즉, 새로운 치료법과 기존 치료법에 차이가 없고), _대립가설(alternative hypothesis)_ 은 새로운 치료법의 중앙 생존이 더 높다는 것입니다(즉, 새로운 치료법과 기존 치료법에 차이가 '통계적으로 유의미함'). 이 시도가 모델링을 통한 전통적인 귀무가설 유의성 검정을 사용하여 평가된 경우 유의성 검정은 데이터에 대한 일련의 가정을 기반으로 하는 사전 정의된 방법론을 사용하여 p-값을 생성합니다. 모델의 결과에서 p-값이 작으면 새로운 치료법이 환자의 수명을 연장하는 데 도움이 된다는 것을 나타내고(if p-value<0.05, 대립가설 채택), p-값에 크면 그러한 차이가 없다는 결론을 내릴 것입니다(if p-value>0.05, 귀무가설 채택). 이러한 증거 부족은 치료가 효과가 없는 것을 포함하여 여러 가지 이유 때문일 수 있습니다.

이러한 유형의 분석에서 중요한 측면은 무엇일까요? 추론 모델링 기술은 일반적으로 p-값, 신뢰 구간 또는 사후 확률과 같은 일부 유형의 확률적 출력을 생성합니다. 일반적으로 그러한 양을 계산하려면 데이터와 데이터를 생성한 기본 프로세스에 대한 공식적인 확률적 가정이 이루어져야 합니다. 통계적 모델링 결과의 품질은 이러한 사전 정의된 가정과 관찰된 데이터가 얼마나 일치하는지에 따라 크게 좌우됩니다. 여기서 가장 중요한 요소는 본질적으로 이론적입니다. “내 데이터가 독립적이고 분포 _X_ 를 따른다면 검정 통계량 _Y_ 를 사용하여 p-값을 생성할 수 있고, 그렇지 않으면 p-값의 결과가 정확하지 않을 수 있다.”는 것입니다.

추론 분석에서 고려해야 할 한가지 측면은 데이터가 모델의 가정과 얼마나 잘 일치하는지 확인하는데 시간이 오래 걸릴 수 있다는 것입니다. 위의 임상 시험 예에서 새로운 치료법이 통계적(및 임상적)으로 유의미하더라도, 현장에서 사용되기까지는 몇 년이 걸릴 수 있으며, 최초 통계 분석이 적절한 결정을 이끌어 냈는지 여부를 독립적으로 평가하기 위해서는 충분한 데이터가 생성되어야 합니다.


### 예측 모델(PREDICTIVE MODELS) {-}

예측 모델은 기존의 데이터를 이용하여 새로운 값을 예측하는 것입니다. 예측 모델의 주요 목표는 예측된 값이 실제 값에 가장 근접하도록 예측하는 것입니다. 

간단한 예는 서점 주인이 다음 달에 자신의 서점으로 특정 서적 몇 권이 배송되어야 할지를 예측하는 것입니다. 과도하게 예측하여 배송되게 되면 공간과 비용의 낭비가 발생하고, 예측이 예상보다 작으면 기회 손실이 발생하고 이익이 줄어듭니다.

이러한 유형의 모델에서 문제 유형은 추론이 아닌 _추정_ 중 하나입니다. 예를 들어, 서점 주인은 일반적으로 “다음 달에 책 _X_ 를 100부 이상 판매할 것인가?”와 같은 질문에는 관심이 없고, 대신 “고객들이 다음 달에 책 _X_ 를 몇 권이나 구매할 것인가?”에 관심이 있습니다. 또한 상황에 따라 예측값이 _왜_ _X_ 인지에 대한 관심이 없을 수도 있습니다. 즉, 데이터와 관련된 형식적 가설을 평가하는 것보다 값 자체에 더 많은 관심이 있습니다. 예측에는 불확실성에 대한 측정값도 포함될 수 있습니다. 서점 주인의 경우 예측 오류를 제공하게 되면 배송받을 수량을 결정하는 데 도움이 될 수 있고, 또한 예측 방법이 얼마나 잘 작동했는지 측정하는 지표 역할을 할 수도 있습니다.

예측 모델에 영향을 미치는 가장 중요한 요소는 무엇일까요? 예측 모델을 생성하는 방법에는 여러 가지가 있으므로 중요한 요소는 모델이 개발된 방식에 따라 달라집니다.

**기계론적 모델**은 가정에 의존하는 모델 방정식을 생성하기 위해 첫 번째 원칙을 사용하여 도출될 수 있습니다. 예를 들어, 특정 시간에 어떤 사람의 몸에 있는 약물의 양을 예측할 때, 약물이 어떻게 투여되고, 흡수되고, 대사되고, 제거되는지 등의 몇 가지 형식을 가정하게 됩니다. 이를 기반으로 일련의 미분 방정식을 사용하여 특정 모델 방정식을 도출할 수 있습니다. 데이터는 이 방정식의 알려지지 않은 매개변수를 추정하는 데 사용되고, 예측이 생성될 수 있습니다. 추론 모델과 마찬가지로 기계론적 예측 모델은 모델 방정식을 정의하는 가정에 크게 의존합니다. 그러나 추론 모델과 달리 기존 기존 데이터를 얼마나 잘 예측하는지에 따라 모델이 얼마나 잘 수행되는지에 대해서 데이터 기반 진술을 쉽게 만들 수 있습니다. 여기서 모델링 실무자를 위한 피드백 루프는 가설 검증보다 훨씬 빠릅니다.

**경험적 구동 모델**은 보다 모호한 가정하에서 생성됩니다. 이러한 모델은 기계 학습 범주에 속하는 경향이 있습니다. 좋은 예는 KNN(K-Nearest Neighbor) 모델입니다. 참조 데이터 세트가 주어지면 참조 세트에서 _K_ 개의 가장 유사한 데이터 값을 사용하여 새 샘플을 예측합니다. 예를 들어 서점 주인이 들여 놓을 새 책에 대한 예측이 필요한 경우 기존 책들의 이력 데이터가 이용될 수 있습니다. 5-최근접 이웃 모델은 들여 놓을 새 책과 가장 유사한 5권의 책(일부 '유사한' 정의의 경우)의 판매 수를 기반으로 들여 놓을 새 책의 양을 추정합니다. 이 모델은 (유사한 책 5권의 평균)예측 구조로만 정의됩니다. 판매량 또는 유사성을 정의하는 데 사용되는 변수에 대한 이론적 또는 확률적 가정은 이루어지지 않습니다. 실제로 모델의 적합성을 평가하는 주요 방법은 기존 데이터를 사용하여 모델의 정확성을 평가하는 것입니다. 이러한 유형의 모델 구조가 좋은 선택이었다면 예측은 실제 값에 가까울 것입니다.

이러한 구분에 대한 보다 광범위한 논의는 @breiman2001 및 @shmueli2010에서 찾을 수 있습니다.

:::rmdnote
모델의 수학적 특성보다는 모델이 사용되는 방식에 따라 모델 유형을 정의했다는 점에 유의하십시오.
:::

일반 선형 회귀 모델은 사용되는 방법에 따라 다음 세 가지 모델 클래스 중 하나에 속할 수 있습니다:

* LOESS와 유사한, _제한된 평활 스플라인(restricted smoothing splines)_ [@Durrleman1989]이라고 불리는 서술적 평활기(descriptive smoother)는 특수 용어를 가진 일반 선형 회귀를 사용하여 데이터의 추세를 설명하는 데 사용할 수 있습니다.

* •	_분산 분석(ANOVA; analysis of variance)_ 모델은 추론에 사용되는 p-값을 생성하는 데 널리 사용되는 방법입니다. ANOVA 모델은 선형 회귀의 특별한 경우입니다.

* 단순 선형 회귀 모델이 매우 정확한 예측을 만들어 내면 예측 모델로 사용할 수 있습니다.

추론에 사용할 수 없는(또는 적어도 사용해서는 안 되는) 예측 모델의 많은 예가 있습니다. 데이터에 대해 확률적 가정이 만들어지더라도 KNN 모델의 특성은 추론에 필요한 수학을 다루기 어렵게 만듭니다.

모델 유형 간에는 추가적인 연관성이 있습니다. 서술 및 추론 모델의 주요 목적은 예측과 관련이 없을 수 있지만 예측 능력을 무시해서는 안 됩니다. 예를 들어, 로지스틱 회귀 분석(Logistic Regression)은 결과가 두 개의 가능한 값을 가진 양적인 데이터에 널리 사용되는 모형이고, 변수가 결과의 확률과 어떤 관련이 있는지 모형화 할 수 있습니다. 로지스틱 회귀 분석(Logistic Regression)이 추론 방식으로 사용될 때는 일반적으로 모델의 _통계적 품질_ 에 많은 주의를 기울입니다. 예를 들어, 분석가는 모형에 포함된 독립 변수 선택에 중점을 두는 경향이 있습니다. 모델 구축을 여러 번 반복하는 것은 일반적으로 결과 변수와 '통계적으로 유의한' 관계가 있는 독립 변수의 최소 하위 집합을 결정하려는 것입니다. 이는 일반적으로 독립 변수의 모든 p-값이 어떤 값(예: 0.05) 미만일 때 달성됩니다(p-value <0.05). 여기에서 분석가는 일반적으로 변수가 결과에 미치는 상대적인 영향에 대한 정성적 진술에 초점을 맞춥니다(예: '나이와 심장병 발병률 사이에는 통계적으로 유의미한 관계가 있습니다.').

통계적 유의성이 모델 품질의 _유일한_ 척도로 사용될 때 위험할 수 있습니다. 통계적으로 최적화된 모델이 모델 정확도가 낮거나 예측 능력의 다른 척도에서 제대로 수행되지 않을 수 있습니다. 모델이 예측에 사용되지 않을 수 있지만, 유의미한 p-값을 갖지만 정확도가 떨어지는 모델에서 추론을 얼마나 신뢰해야 할까요? 예측 성능은 모델의 적합값이 관찰된 데이터에 얼마나 가까운지와 관련된 경향이 있습니다.

:::rmdwarning
모델의 데이터 충실도가 제한된 경우, 모델에서 생성된 추론을 매우 의심해봐야 합니다. 데이터가 충실하지 못한다면 통계적 유의성이 “모델이 적합하다”는 충분한 증거가 아닐 수 있기 때문입니다. 
:::

이것은 직관적으로 명백해 보이지만 실제 데이터 분석에서는 종종 무시됩니다.

## 일부 용어 {#model-terminology}

계속하기 전에 모델링 및 데이터와 관련된 몇 가지 용어에 대해 간략히 설명합니다. 이 설명은 이 책을 읽을 때 도움이 되기 위한 것이지만 완전하지는 않습니다.

첫째, 많은 모델이 _지도(supervised)_ 또는 _비지도 모델(unsupervised)_ 로 분류될 수 있습니다. 비지도 모델은 데이터의 패턴, 클러스터 또는 기타 특성을 학습하지만 결과(예: 종속 변수)가 없는 모델입니다. PCA(주성분 분석), 클러스터링 및 자동 인코더는 비지도 모델의 예입니다. 비지도 모델은 예측 변수와 결과 간의 명시적인 관계없이 변수 또는 변수 집합 간의 관계를 이해하는 데 사용됩니다. 지도 모델은 결과 변수가 있는 모델입니다. 선형 회귀, 신경망 및 기타 수많은 방법론이 이 범주에 속합니다.

지도 모델에는 두 가지 주요 하위 범주가 있습니다:

 * **회귀(Regression)** 는 숫자 결과를 예측합니다.

 * **분류(Classification)** 는 정렬되거나 정렬되지 않은 질적 값의 집합의 결과를 예측합니다.  

위의 정의가 완전하지는 않으며, 가능한 모든 유형의 모델을 설명하지도 않습니다. \@ref(models)장에서 _모델 모드_ 로 이러한 지도 기법의 특성을 다루겠습니다.

다른 변수는, 특히 지도 모델링 분석에서, 다른 _역할_ 을 가질 수 있습니다. 결과(레이블, 끝점 또는 종속 변수라고도 함)는 지도 모델에서 예측되는 값입니다. 결과를 예측하기 위한 기반이 되는 독립 변수는 예측자, 기능 또는 공변량이라고도 합니다(문맥에 의존). 결과와 예측자라는 용어는 이 책에서 가장 자주 사용됩니다.

데이터 또는 변수 자체의 측면에서, 지도 모델이든 비지도 모델이든, 또는 예측자 이든지 결과 이든지 관계없이 두 가지 주요 범주는 양적 또는 질적입니다. 전자의 예로는 `3.14159`와 같은 실수와 `42`와 같은 정수가 있습니다. 명목 데이터라고도 하는 질적 값은 '빨간색', '녹색' 및 '파란색'과 같이 숫자 척도에 자연적으로 배치할 수 없는 일종의 이산 상태를 나타내는 값입니다.


## 모델링이 데이터 분석 프로세스에 어떻게 적합 하는가? {#model-phases}

어떤 상황에서 모델이 생성될까요? 선행하는 단계가 있을까요? 그것이 데이터 분석의 첫 단계인가요?

:::rmdnote
모델링 전에 항상 데이터 분석의 몇 가지 중요한 단계가 있습니다.
:::

첫째, 항상 과소평가되는 **데이터 정리(cleaning the data)** 프로세스가 있습니다. 어떤 상황에서도, 상황에 관계없이 데이터를 조사하여 프로젝트 목표에 적용 가능하고, 정확하며, 적절한지 확인해야 합니다. 이러한 단계는 상황에 따라 나머지 데이터 분석 프로세스보다 더 많은 시간이 소요될 수 있습니다.

두번째는 **데이터 이해(understanding the data)** 라고도 하는 탐색적 데이터 분석(EDA; exploratory data analysis)입니다. 데이터 정리가 탐색적 데이터 분석 단계와 겹칠 수도 있습니다. EDA는 다양한 변수가 서로 어떻게 관련되어 있는지, 어떻게 분포되어 있는지, 일반적인 범위 및 기타 속성을 탐색합니다. 이 단계에서 물어볼 좋은 질문은 '내가 _이_ 데이터를 어떻게 얻었지?'입니다. 이 질문은 데이터가 어떻게 표본 추출 및 여과 되었고, 이러한 작업이 적절한지 어떤지 이해하는 데 도움이 될 수 있습니다. 예를 들어, 데이터베이스 테이블을 병합할 때 병합이 잘못되어 실수로 하나 이상의 하위 모집단이 제거되는 위험을 예방할 수 있습니다. 또 다른 좋은 방법은 데이터가 _적절한지_ 물어보는 것입니다. 예를 들어 환자가 알츠하이머 병에 걸렸는지 여부를 예측할 때, 이 병에 걸린 피실험자와 일반 모집단에서 추출한 건강한 성인에 대한 무작위 표본을 포함하는 데이터 집합을 사용하는 것은 현명하지 않습니다. 질병의 진행적인 특성을 고려할 때, 이 모델은 누가 _가장 나이가 많은 환자_ 인지 단순히 예측할 수 있습니다.

마지막으로 데이터 분석 프로세스를 시작하기 전에 모델의 목표와 성능(및 성공)이 어떻게 판단되는지에 대한 명확한 기대치가 있어야 합니다. 달성할 수 있는 것의 현실적인 목표와 함께 최소한 하나의 _성능 지표(performance metric)_ 를 식별해야 합니다. \@ref장(성능)에서 더 자세히 논의될 일반적인 통계 지표(statistical metrics)는 분류 정확도, 참 및 거짓 긍정 비율, 평균 제곱근 오차(classification accuracy, true and false positive rates, root mean squared error) 등입니다. 이러한 지표의 상대적인 이점과 결점을 고려해야 하고, 측정 지표가 구체적이어야 하며, 광범위한 데이터 분석 목표에 부합하는 것이 중요합니다.

```{r software-data-science-model, echo = FALSE, out.width = '80%', fig.cap = "데이터 과학 프로세스(from R for Data Science).", warning = FALSE}
knitr::include_graphics("premade/data-science-model.svg")
```

데이터를 조사하는 과정은 간단하지 않을 수 있습니다. @wickham2016에는 일반적인 데이터 분석 프로세스에 대한 훌륭한 그림 \@ref(fig:software-data-science-model)를 포함하고 있습니다. 데이터 수집 및 정리/정돈(tidying)이 초기 단계로 표시됩니다. 이해를 위한 분석 단계가 시작되면 경험적 과정이므로 시간이 얼마나 걸릴지 미리 판단할 수 없습니다. 분석, 모델링 및 시각화 주기는 여러 번 반복해야 하는 경우가 많습니다. 

```{r software-modeling-process, echo = FALSE, out.width = '100%', fig.width=8, fig.height=3, fig.cap = "일반적인 모델링 프로세스에 대한 개략도.", warning = FALSE}
knitr::include_graphics("premade/modeling-process.svg")
```

이 반복 프로세스는 특히 모델링에 해당됩니다. 그림 \@ref(fig:software-modeling-process)은 적절한 모델을 결정하는 일반적인 경로를 보여줍니다. 일반적인 단계는 다음과 같습니다:

 * **탐색적 데이터 분석(EDA; Exploratory data analysis):** 처음에는 수치 분석과 데이터의 시각화를 오락가락하며, 서로 다른 발견을 통해 더 많은 질문과 더 많은 이해를 얻기 위한 데이터 분석 "측면 질문"이 도출됩니다.
 
 * **특징 공학(Feature engineering):** EDA를 통해 얻은 이해를 통해 관측된 데이터를 보다 정확하게 모형화할 수 있는 특정 모델 항이 생성됩니다. 여기에는 복잡한 방법론(예: PCA) 또는 보다 단순한 특징(두 예측자의 비율 사용)이 포함될 수 있습니다. \@ref(recipes)장에서 이 중요한 단계를 철저히 다룹니다.
 
 * **모델 튜닝 및 선택(파란색과 노란색 부분이 있는 원):** 다양한 모델을 생성하고 성능을 비교합니다. 일부 모델에는 일부 구조적 매개변수를 지정하거나 최적화해야 하는 _매개변수 튜닝_ 이 필요합니다. 원 안의 색상 세그먼트는 재 표본추출하는 동안에 사용되는 반복 데이터 분할을 나타냅니다 (\@ref(재표본추출)장 참조).
 
 * **모델 평가(Model evaluation):** 모델 개발의 이 단계에서 모델의 성능 지표(performance metrics)를 평가하고, 잔여 플롯을 검사하고, 모델이 얼마나 잘 작동하는지 이해하기 위해 기타 EDA와 유사한 분석을 수행합니다. 경우에 따라 모델 간 공식 비교( \@ref(비교)장)를 통해 모델의 차이가 실험적 잡음 내에 있는지 이해하는 데 도움이 됩니다.
  
이러한 일련의 초기 작업을 거친 후, 어떤 유형의 모델이 우수하고 어떤 하위 모집단이 효과적으로 추정되지 않는지 등 더 많은 이해를 얻을 수 있으며, 추가 EDA, 특징 공학, 또 다른 모델링 등으로 이어집니다. 데이터 분석 목표를 달성한 후 마지막 단계는 일반적으로 모델을 마무리, 문서화 및 전달하는 것입니다. 예측 모델의 경우, 마지막에 특정 목적을 위해 예약된 추가 데이터 집합에서 모델을 검증하는 것이 일반적입니다.

예를 들어 @fes은 시카고 공공 열차 시스템의 일일 승객 수를 모델링하기 위해 날짜, 이전 승객 수, 날씨 및 기타 요인과 같은 예측 변수를 사용합니다. 이러한 데이터를 분석할 때 저자의 '내면의 독백'에 대한 근사치는 다음과 같습니다.

```{r software-monolog, echo = FALSE, results = 'as-is'}
monolog <- 
  tribble(
    ~Activity, ~`Analysis Cycle`, ~Thoughts,
    "EDA", "1",
    "The daily ridership values between stations are extremely correlated.",
    "EDA", " ",
    "Weekday and weekend ridership look very different.",
    "EDA", " ",
    "One day in the summer of 2010 has an abnormally large number of riders.",
    "EDA", "1",
    "Which stations had the lowest daily ridership values?",
    "Feature Engineering", "1",
    "Dates should at least be encoded as day-of-the-week, and year. ",
    "Feature Engineering", " ",
    "Maybe PCA could be used on the correlated predictors to make it easier for the models to use them. ",
    "Feature Engineering", " ",
    "Hourly weather records should probably be summarized into daily measurements. ",
    "Model Fitting", "1",
    "Let’s start with simple linear regression, K-nearest neighbors, and a boosted decision tree. ",
    "Model Tuning", "1",
    "How many neighbors should be used?",
    "Model Tuning", " ",
    "Should we run a lot of boosting iterations or just a few?",
    "Model Tuning", "2",
    "How many neighbors seemed to be optimal for these data? ",
    "Model Evaluation", "2",
    "Which models have the lowest root mean squared errors? ",
    "EDA", "2",
    "Which days were poorly predicted? ",
    "Model Evaluation", "2",
    "Variable importance scores indicate that the weather information is not predictive. We’ll drop them from the next set of models. ",
    "Model Evaluation", " ",
    "It seems like we should focus on a lot of boosting iterations for that model.",
    "Feature Engineering", "2", 
    "We need to encode holiday features to improve predictions on (and around) those dates.",
    "Model Evaluation", "2",
    "Let’s drop K-NN from the model list. "
  )
if (knitr::is_html_output()) {
  tab <- 
    monolog %>% 
    dplyr::select(Thoughts, Activity) %>% 
    kable() %>%
    kable_styling() %>% 
    column_spec(2, width = "25%") %>%
    column_spec(1, width = "75%", italic = TRUE)
} else {
  tab <- 
    monolog %>% 
    dplyr::select(Thoughts, Activity) %>% 
    kable() %>%
    kable_styling()
}
tab
```

기타 등등. 결국에는 충분한 성능을 얻을 수 있는 모델이 선택됩니다.

## 단원 요약 {#software-summary}

이 단원에서는 서술적 모델, 추론 모델 및 예측 모델과 같은 다양한 유형의 모델이 데이터에서 관계를 어떻게 설명하는지에 중점을 두었습니다. 모델의 예측 능력은 주 목표가 예측이 아닌 경우에도 모델을 평가하는 데 사용될 수 있습니다. 모델링 자체는 더 광범위한 데이터 분석 프로세스에 속하며 탐색적 데이터 분석은 고품질 모델을 구축하는 핵심 부분입니다.

모든 종류의 모델링에서 모델 구축을 위한 소프트웨어는 다양한 배경을 가진 실무자들에게 좋은 과학적 방법론과 사용 용이성을 지원해야 합니다. 이를 위해 우리가 개발한  소프트웨어인 tidyverse의 개념과 구문을 사용합니다(\@ref(tidyverse)장에서 소개). \@ref(base-r) 장은 기존의 base R 모델링 기능에 대해 간략히 둘러보고, base R에서 충족되지 않은 요구 사항을 요약합니다.

그런 다음 이 책은 깔끔한 데이터 원칙(tidy data principles)으로 모델링의 기초부터 시작하여 여러 부분으로 나뉩니다. 첫 번째 부분에서는 주택 가격에 대한 예제 데이터 세트를 소개하고 기본적인 tidymodels 패키지를 사용하는 방법을 설명합니다: `r pkg(recipes)`, `r pkg(parsnip)`, `r pkg(workflows)`, `r pkg(yardstick)`, 기타 등등.

책의 두 번째 부분에서는 좋은 모델을 만드는 과정에 대해 자세히 설명합니다. 여기에는 모델 매개변수 튜닝뿐만 아니라 성능에 대한 적절한 추정을 생성하는 것이 포함됩니다.

